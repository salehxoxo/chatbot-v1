{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dd7781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a56be504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ffa0b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo', max_tokens=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00412749",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hazwoperopenai7.pkl\",\"rb\") as f:\n",
    "    db = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08de1dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains import RetrievalQA\n",
    "# from langchain.memory import ConversationBufferWindowMemory\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "# from langchain.chains.question_answering import load_qa_chain\n",
    "# from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f567096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you can only answer osha-hazwoper related questions, don't try to make up an answer. Use five sentences maximum. Keep the answer as concise as possible.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "# doc_chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "# question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8887900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"\n",
    "### Instruction: Use the following pieces of context and chat_history to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use five sentences maximum. Keep the answer as concise as possible.\n",
    "Context: {context}\n",
    "History: {chat_history}\n",
    "### Input: {question}\n",
    "### Response:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "14baae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\",\"question\", \"chat_history\"], template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "79bf6874",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    human_prefix=\"### input\",\n",
    "    ai_prefix=\"### Response\",\n",
    "    input_key=\"question\",\n",
    "    output_key=\"output_text\",\n",
    "    return_messages=False,\n",
    "    k=1\n",
    ")\n",
    "\n",
    "chain = load_qa_chain(\n",
    "    llm, chain_type=\"stuff\", prompt=prompt, memory=memory, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42dbb6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    return_source_documents = True,\n",
    "    retriever=db.as_retriever(search_type = \"similarity\", search_kwargs={\"k\":2}),\n",
    "    verbose=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e021962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "        memory_key='chat_history', return_messages=True, k=1, input_key='question', output_key='answer'\n",
    "    )\n",
    "qa_chain2 = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":1}),\n",
    "        verbose=True,\n",
    "        memory=memory,\n",
    "        return_source_documents=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0455b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=prompt, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90f57c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "str = \"Strictly answer using the context. Otherwise, say 'I can only answer Hazwoper-related Questions.'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2beca21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Do you provide demo classe?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3eb0991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db.similarity_search(question,k=2)\n",
    "# docs = db.max_marginal_relevance_search(question,k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "43c13889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='title\\nTrent Waylon, Safety and Occupational Health Specialist\\ndescription\\n“Got a demo and discussed my needs with their team. Am incredibly pleased, how quickly they provided a detailed documented solution.\"\\nmeta_description\\nNone\\nPage Type\\nTestimonials\\n####################', metadata={'source': './Trent Waylon Safety and Occupational Health Specialist-Testimonials.txt'}),\n",
       " Document(page_content='####################', metadata={'source': './Overview-Online Course(21).txt'})]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a519fb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1b507e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Do you provide demo classe?',\n",
       " 'result': 'Yes, we provide demo classes.',\n",
       " 'source_documents': [Document(page_content='title\\nTrent Waylon, Safety and Occupational Health Specialist\\ndescription\\n“Got a demo and discussed my needs with their team. Am incredibly pleased, how quickly they provided a detailed documented solution.\"\\nmeta_description\\nNone\\nPage Type\\nTestimonials\\n####################', metadata={'source': './Trent Waylon Safety and Occupational Health Specialist-Testimonials.txt'}),\n",
       "  Document(page_content='####################', metadata={'source': './Overview-Online Course(21).txt'})]}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0702a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"E:\\\\saleh\\\\gpt4all-converted.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b346c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "callbacks = [StreamingStdOutCallbackHandler()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8fbf8e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  E:\\\\saleh\\\\gpt4all-converted.bin\n"
     ]
    }
   ],
   "source": [
    "llm = GPT4All(model=local_path, callbacks=callbacks, verbose=True)\n",
    "# llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7af244da",
   "metadata": {},
   "outputs": [],
   "source": [
    " custom_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question. Preserve the ogirinal question in the answer setiment during rephrasing.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    " CONDENSE_QUESTION_PROMPT_CUSTOM = PromptTemplate.from_template(custom_template)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cafd9cc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PROMPT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m qa \u001b[38;5;241m=\u001b[39m ConversationalRetrievalChain\u001b[38;5;241m.\u001b[39mfrom_llm(llm, db\u001b[38;5;241m.\u001b[39mas_retriever(search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m}),combine_docs_chain_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mPROMPT\u001b[49m},verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,condense_question_prompt\u001b[38;5;241m=\u001b[39mCONDENSE_QUESTION_PROMPT_CUSTOM )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PROMPT' is not defined"
     ]
    }
   ],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(llm, db.as_retriever(search_kwargs={\"k\": 1,\"search_type\":\"similarity\"}),combine_docs_chain_kwargs={'prompt': PROMPT},verbose=True,condense_question_prompt=CONDENSE_QUESTION_PROMPT_CUSTOM )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f886513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
